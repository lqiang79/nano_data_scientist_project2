{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitvenvvenv2ccbef07ed2c4181ad3d11c165ec2bbf",
   "display_name": "Python 3.7.5 64-bit ('venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to /Users/qiangli/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /Users/qiangli/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/qiangli/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/qiangli/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download(['punkt', 'wordnet','averaged_perceptron_tagger', 'stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>original</th>\n      <th>genre</th>\n      <th>related</th>\n      <th>request</th>\n      <th>offer</th>\n      <th>aid_related</th>\n      <th>medical_help</th>\n      <th>medical_products</th>\n      <th>search_and_rescue</th>\n      <th>...</th>\n      <th>aid_centers</th>\n      <th>other_infrastructure</th>\n      <th>weather_related</th>\n      <th>floods</th>\n      <th>storm</th>\n      <th>fire</th>\n      <th>earthquake</th>\n      <th>cold</th>\n      <th>other_weather</th>\n      <th>direct_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Weather update - a cold front from Cuba that c...</td>\n      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Is the Hurricane over or is it not over</td>\n      <td>Cyclone nan fini osinon li pa fini</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Looking for someone but no name</td>\n      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>says: west side of Haiti, rest of the country ...</td>\n      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 39 columns</p>\n</div>",
      "text/plain": "                                             message  \\\n0  Weather update - a cold front from Cuba that c...   \n1            Is the Hurricane over or is it not over   \n2                    Looking for someone but no name   \n3  UN reports Leogane 80-90 destroyed. Only Hospi...   \n4  says: west side of Haiti, rest of the country ...   \n\n                                            original   genre  related  \\\n0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n1                 Cyclone nan fini osinon li pa fini  direct        1   \n2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n\n   request  offer  aid_related  medical_help  medical_products  \\\n0        0      0            0             0                 0   \n1        0      0            1             0                 0   \n2        0      0            0             0                 0   \n3        1      0            1             0                 1   \n4        0      0            0             0                 0   \n\n   search_and_rescue  ...  aid_centers  other_infrastructure  weather_related  \\\n0                  0  ...            0                     0                0   \n1                  0  ...            0                     0                1   \n2                  0  ...            0                     0                0   \n3                  0  ...            0                     0                0   \n4                  0  ...            0                     0                0   \n\n   floods  storm  fire  earthquake  cold  other_weather  direct_report  \n0       0      0     0           0     0              0              0  \n1       0      1     0           0     0              0              0  \n2       0      0     0           0     0              0              0  \n3       0      0     0           0     0              0              0  \n4       0      0     0           0     0              0              0  \n\n[5 rows x 39 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///../data//DisasterResponse.db')\n",
    "df = pd.read_sql_table('messages_categories', con=engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df.iloc[:, 4:]\n",
    "category_names = df.columns[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" tokenize word in text\n",
    "\n",
    "    Args:\n",
    "        text {string} -- text \n",
    "\n",
    "    Returns:\n",
    "        tokenized words list\n",
    "    \"\"\"\n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    # Reduce words to their root form\n",
    "    words = [WordNetLemmatizer().lemmatize(word, pos='n') for word in words]\n",
    "    words = [WordNetLemmatizer().lemmatize(word, pos='v') for word in words]\n",
    "    words = [WordNetLemmatizer().lemmatize(word, pos='a') for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[773])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['carrefour', 'feuille', 'extend', 'need', 'help', 'wait']\n"
    }
   ],
   "source": [
    "print( tokenize(X[122]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [WordNetLemmatizer().lemmatize(word) for word in stemmed]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
    "words = [WordNetLemmatizer().lemmatize(w, pos='n') for w in words]\n",
    "words = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "words = [WordNetLemmatizer().lemmatize(w, pos='a') for w in words]\n",
    "print(words)"
   ]
  }
 ]
}